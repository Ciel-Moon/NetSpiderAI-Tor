# NetSpiderAI-Tor

Declarationï¼š
ğŸ‘‹ Hi, I'm the author
Hello! I'm an 8th grader from China, and this is my personal project â€” I'm working hard on the coding part ğŸš€
Since I'm still learning, the code might not be perfect, and updates may be a bit slow (school comes first ğŸ˜…), but I'll do my best to maintain it.
If you spot any issues or have suggestions, feel free to reach out. Thanks so much for your understanding and support!
ğŸ“§ Contact: Cedric-Shadow@outlook.com

Now,the main text follows below.

NetSpiderAI-Tor: The Next-Generation Anonymous Web Crawler Browser

NetSpiderAI-Tor is a revolutionary, enterprise-grade web crawler that combines the privacy architecture of the Tor Browser with advanced AIâ€‘driven crawling capabilities. It provides a clean, browser-like graphical interface, robust anonymity features, and a full suite of tools for largeâ€‘scale data extraction.

---

ğŸŒŸ Key Features

Â· Tor Network Integration
    Full onion routing with automatic IP rotation, bridge support, and identity renewal. Your real IP stays hidden.
Â· Dual Rendering Engines
    Choose between Playwright (faster) and Selenium (wider compatibility) to crawl JavaScriptâ€‘heavy sites.
Â· Intelligent Compliance
    Respects robots.txt and HTTP 403/401 errors by prompting the user â€“ with an option to forceâ€‘crawl if desired.
Â· Automated Proxy Pool
    Continuously fetches, validates, and rotates free proxies. Falls back to a local pool when Tor is not used.
Â· Distributed Task Scheduling
    RabbitMQâ€‘based queue allows multiple crawler nodes to work together. Builtâ€‘in backpressure control.
Â· Resumable Downloads
    Large files (images, videos) are downloaded in chunks and can be resumed after interruption.
Â· Modern GUI
    Built with CustomTkinter â€“ clean, responsive, and supports systemâ€‘theme switching (dark/light).
Â· Data Persistence
    SQLite/MySQL storage for crawled content, with JSON/CSV export. Deduplication and incremental updates.

---

ğŸš€ Quick Start

Prerequisites

Â· Python 3.8+
Â· Tor service (optional, for anonymous mode)
Â· RabbitMQ server (optional, for distributed mode)

Installation

```bash
# Clone the repository
git clone https://github.com/yourname/NetSpiderAI-Tor.git
cd NetSpiderAI-Tor

# Install Python dependencies
pip install -r requirements.txt

# Install Tor (Ubuntu/Debian)
sudo apt-get install tor
sudo systemctl start tor

# Install RabbitMQ (Ubuntu/Debian)
sudo apt-get install rabbitmq-server
sudo systemctl start rabbitmq-server
```

Running the Application

```bash
python main.py
```

First-Time Setup

1. Go to Settings tab.
2. Configure Tor ports (default SOCKS 9050, Control 9051).
3. Choose the rendering engine (Playwright recommended).
4. Set download directory and database path.

---

ğŸ“– User Guide

Basic Crawling

1. Enter a URL in the address bar.
2. Select a privacy mode:
   Â· Normal â€“ direct connection (no proxy)
   Â· Anonymous â€“ uses the proxy pool
   Â· Tor â€“ routes all traffic through the Tor network
3. Click Crawl.
4. Extracted text appears in the main panel; images and videos are automatically saved to downloads/.

Handling Dynamic Content

If the target site relies on JavaScript, enable the Dynamic Rendering checkbox before crawling. The engine will wait for the page to fully render.

Task Monitoring

Switch to the Task Monitor tab to see all running and completed tasks. You can pause, resume, or cancel individual jobs.

Data Export

In the Settings tab, click Export Data to save crawled content as JSON or CSV. You can also export by task ID.

---

ğŸ”§ Architecture Overview

```
NetSpiderAI-Tor/
â”‚
â”œâ”€â”€ main.py                 # Entry point
â”œâ”€â”€ config/                 # Global configuration
â”œâ”€â”€ core/                   # Core modules
â”‚   â”œâ”€â”€ tor_manager.py      # Tor circuit management
â”‚   â”œâ”€â”€ crawler_engine.py   # Playwright/Selenium engines
â”‚   â”œâ”€â”€ proxy_pool.py       # Automatic proxy collector/validator
â”‚   â”œâ”€â”€ downloader.py       # Resumable file downloader
â”‚   â”œâ”€â”€ scheduler.py        # RabbitMQ task scheduler
â”‚   â””â”€â”€ robots_checker.py   # robots.txt parser
â”œâ”€â”€ gui/                     # CustomTkinter interface
â”œâ”€â”€ storage/                 # Database and file management
â”œâ”€â”€ utils/                   # Helpers (Userâ€‘Agent, logger, etc.)
â””â”€â”€ data/                    # Downloads, logs, database
```

Core Components

Â· TorManager â€“ starts/stops Tor, renews identity, provides a SOCKS5 proxy session.
Â· DynamicCrawler â€“ unified interface for Playwright/Selenium; randomises browser fingerprint.
Â· ProxyPool â€“ fetches from public proxy lists, validates them, and serves reliable proxies.
Â· ResumableDownloader â€“ splits large files into chunks, supports Range headers.
Â· DistributedScheduler â€“ RabbitMQ producer/consumer with priority queues and worker coordination.
Â· Database â€“ SQLite (default) with optional MySQL support; stores tasks, content, and media records.

---

âš™ï¸ Configuration

All settings are managed through config/settings.py or the GUI. Key options:

Setting Description Default
TOR_SOCKS_PORT Tor SOCKS5 port 9050
TOR_CONTROL_PORT Tor control port 9051
RENDERING_ENGINE playwright / selenium / requests playwright
PROXY_TEST_URL URL used to validate proxies httpbin.org/ip
DOWNLOAD_DIR Where media files are saved ./data/downloads
DATABASE_URL SQLite path or MySQL connection string sqlite:///data/db/spider.db
RABBITMQ_HOST RabbitMQ server address localhost

---

ğŸ¤ Contributing

We welcome contributions of all kinds â€“ bug reports, feature requests, documentation improvements, and code.

1. Fork the repository.
2. Create a feature branch (git checkout -b feature/AmazingFeature).
3. Commit your changes (git commit -m 'Add some AmazingFeature').
4. Push to the branch (git push origin feature/AmazingFeature).
5. Open a Pull Request.

Please ensure your code passes existing tests and, if adding new functionality, include appropriate tests.

---

ğŸ“„ License

Distributed under the MIT License. See LICENSE for more information.

---

ğŸ™ Acknowledgements

Â· Tor Project â€“ for the onion routing technology.
Â· CustomTkinter â€“ for the modern GUI toolkit.
Â· Playwright â€“ for reliable browser automation.
Â· RabbitMQ â€“ for the distributed messaging system.

---

NetSpiderAI-Tor is more than a crawler â€“ it's a privacyâ€‘first, enterpriseâ€‘ready data acquisition platform. Start using it today and experience the next generation of web intelligence.
